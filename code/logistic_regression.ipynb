{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2804969e-b4b0-41e4-8851-4f1535076355",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d5c6d5-ff23-4548-b0cc-605ad0951aa5",
   "metadata": {},
   "source": [
    "# **Load and clean the training data**\n",
    "\n",
    "We load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122f5c21-3d35-4ffa-be0a-ceb554346465",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 328135 samples and 321 features !\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"../data\")\n",
    "\n",
    "print(f\"The data has {x_train.shape[0]} samples and {x_train.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af58328-3e1e-4ab3-a14c-48dceb0e7f6d",
   "metadata": {},
   "source": [
    "We then clean the data by : \n",
    "- removing the nan values by the mean of the rest of the feature\n",
    "- removing the features where the variance is zero since they are constants for all samples\n",
    "- remove the 8 first features as the appear weird in the task of predicting a heart attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d4ae66-b516-4139-a8f2-2512e785e3bc",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "xt_feat = x_train\n",
    "xt_feat = preprocessing(xt_feat)\n",
    "xt_feat = gen_clean(xt_feat, [], np.arange(321))\n",
    "print(f\"The data has now {xt_feat.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2183b026-23d6-4c69-971a-1d6f7690d029",
   "metadata": {},
   "source": [
    "# PCA algorithm implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a510c5-61e7-4087-b63a-8fa1a0dbbb82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_indices, idx = pca(xt_feat)\n",
    "print(f\"We can keep the {idx} first most influent features given by pca_indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2484956-3861-4d1d-b7f5-a4eb1fde6290",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_pca = xt_feat[:, pca_indices]\n",
    "x_train_pca = xt_feat[:, :idx]\n",
    "\n",
    "print(f\"The data has now {x_train_pca.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8528a1e6-524f-4810-9e74-fab4643346dd",
   "metadata": {},
   "source": [
    "# Logistic regression using stochastic gradient descent (SGD)\n",
    "\n",
    "We train our model using logistic regression using SGD with mean-square error.\n",
    "\n",
    "First, we separate our data in a training set(70%) and testing set(30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70178b3-4a8b-4784-bf84-6b59ac3dacde",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tx_tr, tx_te, y_tr, y_te = cross(x_train_pca, y_train, 0.48)\n",
    "\n",
    "print(f\"tx_tr shape : {tx_tr.shape} ; tx_te shape : {tx_te.shape}\")\n",
    "print(f\"       y_tr : {y_tr.shape}     ;        y_te : {y_te.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0779560-bcd8-4c8e-a440-7a6c831df032",
   "metadata": {},
   "source": [
    "Now we build our models for linear regression using SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e8245c8-0473-432d-804d-a33d2aa8b190",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has now 191 features !\n"
     ]
    }
   ],
   "source": [
    "y, tx = build_model_data(tx_tr, y_tr)\n",
    "y_test, tx_test = build_model_data(tx_te, y_te)\n",
    "print(f\"The data has now {tx.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad76574-befc-4279-b387-98b2b18822a8",
   "metadata": {},
   "source": [
    "## Training \n",
    "\n",
    "Here we train our model using SGD with MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235fd6aa-b9db-4b84-b598-1e9beca270bb",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(tx.shape[1])\n",
    "degree = range(1,4)\n",
    "gammas = np.logspace(-5, 0, 15)\n",
    "max_iters = 2000\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "best_degree, best_gamma, best_loss = logistic_regression_demo(tx, y, gammas, degree, max_iters)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "print(\n",
    "    \"The best rmse of %.3f is obtained for a degree of %.f and a lambda of %.5f.\"\n",
    "    % (best_loss, best_degree, best_gamma)\n",
    ")\n",
    "\n",
    "print(f\"Execution time {(end_time - start_time).total_seconds()} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95a07ea0-31f4-453a-b1c4-f8073d798d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time 106.096183 seconds\n"
     ]
    }
   ],
   "source": [
    "best_gamma = 1e-05\n",
    "initial_w = np.zeros(tx.shape[1])\n",
    "max_iters = 2000\n",
    "\n",
    "w, loss = logistic_regression(y, tx, initial_w, max_iters, best_gamma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a50a196-c27e-42e0-b245-ca55a7a82ba9",
   "metadata": {},
   "source": [
    "### Computation of metrics\n",
    "\n",
    "We first compute some metrics on the training data (60% of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "best_thresh = best_threshold(y, tx, w)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c8caf34b-65d1-4bc8-a682-a226626d8b53",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.80736997155628%\n",
      "Precision: 29.611122305057425%\n",
      "Recall : 53.20782041998552%\n",
      "F1-score : 38.04789644012945%\n"
     ]
    }
   ],
   "source": [
    "pred_data = np.dot(tx, w)\n",
    "\n",
    "pred_data[pred_data > best_thresh] = 1\n",
    "pred_data[pred_data <= best_thresh] = -1\n",
    "\n",
    "correctly_classified_data = np.sum(pred_data == y)\n",
    "\n",
    "tp = np.sum((pred_data == 1) & (y == 1))\n",
    "fp = np.sum((pred_data == 1) & (y == -1))\n",
    "\n",
    "tn = np.sum((pred_data == -1) & (y == -1))\n",
    "fn = np.sum((pred_data == -1) & (y == 1))\n",
    "\n",
    "accuracy_data = (tp + tn)/(tp + fp + tn + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_data*100}%\")\n",
    "print(f\"Precision: {tp/(tp + fp)*100}%\")\n",
    "print(f\"Recall : {tp/(tp + fn)*100}%\")\n",
    "print(f\"F1-score : {tp/(tp + 0.5*(fn + fp))*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f5dea0-18a8-4df9-be75-271fdec36923",
   "metadata": {},
   "source": [
    "Now we compute some metrics for our test data (40% of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12e0ac7d-077c-4d10-9fb2-ea0fad434b4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 84.63585163305612%\n",
      "Precision: 29.38323196895638%\n",
      "Recall : 51.92878338278932%\n",
      "F1-score : 37.530381737597104%\n"
     ]
    }
   ],
   "source": [
    "pred_test = np.dot(tx_test, w)\n",
    "\n",
    "pred_test[pred_test > best_thresh] = 1\n",
    "pred_test[pred_test <= best_thresh] = -1\n",
    "\n",
    "correctly_classified_test = np.sum(pred_test == y_test)\n",
    "\n",
    "tp = np.sum((pred_test == 1) & (y_test == 1))\n",
    "fp = np.sum((pred_test == 1) & (y_test == -1))\n",
    "\n",
    "tn = np.sum((pred_test == -1) & (y_test == -1))\n",
    "fn = np.sum((pred_test == -1) & (y_test == 1))\n",
    "\n",
    "accuracy_test = (tp + tn)/(tp + fp + tn + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_test*100}%\")\n",
    "print(f\"Precision: {tp/(tp + fp)*100}%\")\n",
    "print(f\"Recall : {tp/(tp + fn)*100}%\")\n",
    "print(f\"F1-score : {tp/(tp + 0.5*(fn + fp))*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d7fb00-7b20-4af7-a5da-d94da53ae980",
   "metadata": {},
   "source": [
    "# Prediction on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e483fd-5a01-4703-8f04-bdc8e51989cf",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "tx_test = x_test\n",
    "tx_test = preprocessing(x_test)\n",
    "tx_test = gen_clean(tx_test, [], np.arange(321))\n",
    "\n",
    "tx_test = tx_test[:, pca_indices]\n",
    "tx_test = tx_test[:, :idx]\n",
    "tx_test = np.c_[np.ones(tx_test.shape[0]), tx_test]\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "print(f\"Execution time {(end_time - start_time).total_seconds()} seconds\")\n",
    "print(f\"The data has {tx_test.shape[0]} samples and {tx_test.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0eba11-ae4a-4888-81f2-44cd14cc9690",
   "metadata": {
    "tags": [],
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "pred_te = np.dot(tx_test, w)\n",
    "\n",
    "pred_te[pred_te > best_thresh] = 1\n",
    "pred_te[pred_te < best_thresh] = -1\n",
    "\n",
    "indices_one = np.where(pred_te == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b0548600-a0f1-4cde-ac48-8b8499dc9a99",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_csv_submission(test_ids, pred_te, \"../data/log_reg.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}