{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38cfce00-7596-4f51-aa1c-5750258f0d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927ddbc4-74dd-4b7e-bc8e-39c4775c6340",
   "metadata": {},
   "source": [
    "# **Load the training data**\n",
    "\n",
    "We load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a0894-6252-4b01-9c74-9b10d37bf93b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "from implementations import *\n",
    "\n",
    "data_load = load_data(\"x_train.csv\")\n",
    "pred = load_data(\"y_train.csv\")\n",
    "print(f\"The data has {data_load.shape[0]} samples and {data_load.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878ab50a-2f67-4ebb-9851-fa7b7b380886",
   "metadata": {},
   "source": [
    "We clean the data by removing the nan values by the mean of the rest of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dc8496-7e54-4639-97ec-b2895e7d84bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = np.ones(data_load.shape)\n",
    "stds = np.array([])\n",
    "for i in range(data.shape[1]):\n",
    "    d, std = standardize_clean(data_load[:, i])\n",
    "    data[:, i] = d\n",
    "    stds = np.append(stds, std)\n",
    "print(stds.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f849c-709f-4fd0-8a54-a1f7b0d51a1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "We further clean the data by removing the features where the variance is zero since they are constants for all samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207b1a97-b052-47c1-956c-d0fefeeefc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "indices = np.where(stds != 0)\n",
    "data_var = data[:, indices]\n",
    "data_var = np.squeeze(data_var, axis = 1)\n",
    "print(data_var.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693df8b2-ed9b-4548-8468-54e6685eaa16",
   "metadata": {
    "tags": []
   },
   "source": [
    "We also remove the 8 first features as the appear weird in the task of predicting a heart attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d49aa9a-539b-4ab5-9173-2d3b56ea8c9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_cleaned = data_var[:, 9:]\n",
    "print(data_cleaned.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0022b951-01ae-482a-9a91-bdc6878fa522",
   "metadata": {},
   "source": [
    "We then separe the data to train on 60% of the total and to test it on the remaining 40% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8786b70-cd4e-487e-8442-83b524d98912",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_size = np.floor(data_cleaned.shape[0] * 0.6).astype(int)\n",
    "data_cross = data_cleaned[:train_size, :]\n",
    "pred_cross = pred[:train_size]\n",
    "data_test = data_cleaned[train_size:, :]\n",
    "pred_test = pred[train_size:]\n",
    "print(f\"Cross shape : {data_cross.shape} ; Test shape : {data_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efc066a-74cb-4e6b-9207-61906787dc92",
   "metadata": {},
   "source": [
    "Now we build our models for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4519d9-76e2-4a60-97fe-9a1890f7cf25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y, tx = build_model_data(data_cross, pred_cross)\n",
    "y_test, tx_test = build_model_data(data_test, pred_test)\n",
    "print(f\"The data has now {tx.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84cb632-ef6f-4cce-9276-2f95f9f1b903",
   "metadata": {},
   "source": [
    "## Linear regression using gradient descent\n",
    "\n",
    "Here we train our model using GD with MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae0c7fd-20c1-403e-a175-9b348f5cc4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "initial_w = np.zeros(tx.shape[1])\n",
    "max_iters = 100\n",
    "gamma = 0.09\n",
    "\n",
    "start_time = datetime.datetime.now()\n",
    "w, loss = mean_squared_error_gd(y, tx, initial_w, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "print(f\"Execution time {(end_time - start_time).total_seconds()} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41fde6c-4da2-4e82-bbff-8f67e4f9fd0d",
   "metadata": {},
   "source": [
    "### Computation of metrics\n",
    "\n",
    "We first compute some metrics on the training data (60% of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49f21d6-55c5-4fbf-ac2e-78a14ff9164b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_data = np.dot(tx, w)\n",
    "pred_data = (pred_data > 0.49).astype(float)\n",
    "correctly_classified_data = np.sum(pred_data == y)\n",
    "\n",
    "tp = np.sum((pred_data == 1) & (y == 1))\n",
    "fp = np.sum((pred_data == 1) & (y == 0))\n",
    "\n",
    "tn = np.sum((pred_data == 0) & (y == 0))\n",
    "fn = np.sum((pred_data == 0) & (y == 1))\n",
    "\n",
    "accuracy_data = (tp + tn)/(tp + fp + tn + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_data*100}%\")\n",
    "print(f\"True positive rate: {tp/(tp + fp)*100}%\")\n",
    "print(f\"True negative rate: {tn/(tn + fn)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56d6c6f-feba-49c0-9223-ca63a8d2d8e5",
   "metadata": {},
   "source": [
    "Now we compute some metrics for our test data (40% of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56741a7a-76d9-48fc-8b0a-71dd68b24923",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_test = np.dot(tx_test, w)\n",
    "pred_test = (pred_test > 0.49).astype(float)\n",
    "correctly_classified_test = np.sum(pred_test == y_test)\n",
    "\n",
    "tp = np.sum((pred_test == 1) & (y_test == 1))\n",
    "fp = np.sum((pred_test == 1) & (y_test == 0))\n",
    "\n",
    "tn = np.sum((pred_test == 0) & (y_test == 0))\n",
    "fn = np.sum((pred_test == 0) & (y_test == 1))\n",
    "\n",
    "accuracy_test = (tp + tn)/(tp + fp + tn + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_test*100}%\")\n",
    "print(f\"True positive rate: {tp/(tp + fp)*100}%\")\n",
    "print(f\"True negative rate: {tn/(tn + fn)*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94441704-eea1-42f3-8439-3bdac8b04b43",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dfe6db-247e-4671-a14d-6ded5d77eb67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.bar(range(len(w)), np.abs(w))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Weight Value')\n",
    "plt.title('Feature Weights for Analysis')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0f4e66-4959-4f6f-bfa5-87e091c6f6bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fddb54-26cc-4208-b93b-77f0f4413428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
