{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "597b3519-d9f5-41ef-b50e-4a6713f922cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from implementations import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbd34a3-b2d3-4988-b1f3-807851544ac4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# **Load and clean the training data**\n",
    "\n",
    "We load the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c654f63-ff83-43cb-82a6-347760475597",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has 328135 samples and 321 features !\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, train_ids, test_ids = load_csv_data(\"../data\")\n",
    "\n",
    "print(f\"The data has {x_train.shape[0]} samples and {x_train.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464fbaa8-19ef-4c72-a12c-14cabbc9058f",
   "metadata": {
    "tags": []
   },
   "source": [
    "For each feature, we clean the data so the values make more sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f99e3427-7234-4755-9190-6724954f3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : clean the data by calling the associated function in the implementations.py\n",
    "x_train[:,6] = replace(x_train[:,6], [1100,1200], [1,0])\n",
    "x_train[:,13] = replace(x_train[:,13], [0,1], [1,2])\n",
    "x_train[:,24] = replace(x_train[:,24], [1,2,7,9], [0,1,np.nan,np.nan])\n",
    "x_train[:,25] = replace(x_train[:,25], [77,99], [np.nan,np.nan])\n",
    "x_train[:,26] = replace(x_train[:,26], [2,3,4,5,7,9], [0.75,0.5,0.25,0,np.nan,np.nan])\n",
    "\n",
    "array_1 = [27,28,29]\n",
    "\n",
    "for i in array_1 : \n",
    "    x_train[:,i] = replace(x_train[:,i], [88,77,99], [np.nan,np.nan,np.nan])\n",
    "\n",
    "x_train[:,31] = replace(x_train[:,31], [3,7,9], [0,np.nan,np.nan])\n",
    "\n",
    "array_2 = [30,32,34,35,36,38,39,40,41,42,43,44,45,46,47,48,53,54,55,56,57,61,64,65,66,67,68,69,70,71,72,73,74,87,95,96,100,103,104,107,108,116,117,118]\n",
    "           \n",
    "for i in array_2:\n",
    "    x_train[:,i] = replace(x_train[:,i], [7,9], [np.nan,np.nan])\n",
    "    \n",
    "\n",
    "x_train[:,33] = replace(x_train[:,33], [1,2,3,4,7,8,9], [6,18,42,60,np.nan,120,np.nan])\n",
    "x_train[:,37] = replace(x_train[:,37], [1,2,3,4,7,9], [6,18,42,60,np.nan,np.nan])\n",
    "x_train[:,49] = replace(x_train[:,49], [98,99], [np.nan,np.nan])\n",
    "\n",
    "array_3 = [51,52,58]\n",
    "\n",
    "for i in array_3 : \n",
    "    x_train[:,i] = replace(x_train[:,i], [9], [np.nan])\n",
    "    \n",
    "x_train[:,59] = replace(x_train[:,59], [88,99], [0,np.nan])\n",
    "x_train[:,60] = replace(x_train[:,60], [1,2,3,4,5,6,7,8,77,99] , [5,12.5,17.5,22.5,30,42.5,62.5,75,np.nan,np.nan])\n",
    "\n",
    "x_train[:,62] = replace(x_train[:,62], [7777,9999], [np.nan,np.nan])    \n",
    "x_train[:,62] = list(map(IntoPounds,(x_train[:, 62])))\n",
    "\n",
    "x_train[:,63] = replace(x_train[:,63], [7777,9999], [np.nan,np.nan])    \n",
    "x_train[:,63] = list(map(IntoInches,(x_train[:, 63])))\n",
    "\n",
    "x_train[:,75] = replace(x_train[:,75],[1,2,3,4,5,6,7,8,77,99] , [15,60,135,270,1080,2070,3600,np.nan,np.nan,np.nan])\n",
    "x_train[:,76] = replace(x_train[:,76],[3,7,9] ,[0,np.nan,np.nan])\n",
    "x_train[:,77] = replace(x_train[:,77],[777,888,999] ,[np.nan,0,np.nan])\n",
    "x_train[:,77] = list(map(WeekToMonth,(x_train[:, 77])))\n",
    "\n",
    "\n",
    "array_5 = [78,80,88,91,98,119]\n",
    "\n",
    "for i in array_5 :\n",
    "    x_train[:,i] = replace(x_train[:,i], [77,99], [np.nan,np.nan])\n",
    "    \n",
    "x_train[:,79] = replace(x_train[:,79],[77,88,99] ,[np.nan,0,np.nan])\n",
    "\n",
    "array_6 = [81,82,83,84,85,86]\n",
    "\n",
    "for i in array_6 :\n",
    "    x_train[:,i] = replace(x_train[:,i], [300,555,777,999], [0,0,np.nan,np.nan])\n",
    "    x_train[:,i] = list(map(DayToMonth,(x_train[:, i])))\n",
    "    \n",
    "array_7 = [89,90,92,93] \n",
    "\n",
    "for i in array_7 :\n",
    "    x_train[:,i] = replace(x_train[:,i], [777,999],  [0,0,np.nan,np.nan])\n",
    "\n",
    "x_train[:,89] = list(map(WeekToMonth,(x_train[:, 89])))\n",
    "x_train[:,90] = list(map(HourToMinutes,(x_train[:, 90])))\n",
    "x_train[:,92] = list(map(HourToMinutes,(x_train[:, 92])))\n",
    "\n",
    "array_8 = [94,110,111] \n",
    "\n",
    "for i in array_8 :\n",
    "    x_train[:,i] = replace(x_train[:,i], [777,888,999], [np.nan,0,np.nan])\n",
    "\n",
    "x_train[:,94] = replace(x_train[:,94], [777,888,999], [np.nan,0,np.nan])\n",
    "x_train[:,94] = list(map(WeekToMonth,(x_train[:, 94])))\n",
    "x_train[:,97] = replace(x_train[:,97], [2,3,7,9], [0.5,0,np.nan,np.nan])\n",
    "x_train[:,99] = replace(x_train[:,99], [2,3,4,5,7,8,9], [0.75,0.5,0.25,0,np.nan,np.nan,np.nan])\n",
    "x_train[:,101] = replace(x_train[:,101], [777777, 999999],  [np.nan,np.nan])\n",
    "\n",
    "#x_train[:,101] = list(map(DateType,(x_train[:, 101])))\n",
    "\n",
    "x_train[:,105] = replace(x_train[:,105], [777777, 999999],  [np.nan,np.nan])\n",
    "#x_train[:,105] = list(map(DateType,(x_train[:, 105])))\n",
    "\n",
    "x_train[:,110] = list(map(DayToYear,(x_train[:, 110])))\n",
    "x_train[:,111] = list(map(DayToYear,(x_train[:, 111])))\n",
    "\n",
    "x_train[:,113] = replace(x_train[:,113],[77,88,98,99] ,[np.nan,0,np.nan,np.nan])\n",
    "x_train[:,114] = replace(x_train[:,114],[77,88,99] ,[np.nan,0,np.nan])\n",
    "x_train[:,115] = replace(x_train[:,114],[1,2,3,4,7,8,9] ,[15,180,540,720,np.nan,0,np.nan])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c45591a-1eb8-4e1e-b7c1-600d53bcd6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[:, 240] = replace(x_train[:, 240], [np.nan, 77, 99], [-1, -1, -1])\n",
    "x_train[:, 246] = replace(x_train[:, 246], [np.nan, 14], [-1, -1])\n",
    "x_train[:, 247] = replace(x_train[:, 247], [np.nan, 3], [-1, -1])\n",
    "x_train[:, 252] = replace(x_train[:, 252], [np.nan, 99999], [np.nan, np.nan])\n",
    "x_train[:, 261] = replace(x_train[:, 261], [np.nan, 7, 9], [-1, -1, -1])\n",
    "x_train[:, 262] = replace(x_train[:, 262], [np.nan, 900], [-1, -1])\n",
    "x_train[:, 298] = replace(x_train[:, 298], [np.nan, 9], [1, 1])\n",
    "\n",
    "rep_one = [241, 242, 243, 244, 255, 256, 257, 258, 259, 260, 263, 265, 278, 279, 284, \n",
    "          305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320]\n",
    "\n",
    "for i in rep_one : \n",
    "    x_train[:, i] = replace(x_train[:, i], [np.nan, 9], [-1, -1])\n",
    "    \n",
    "rep_two = [245, 249, 254, 289, 290, 291, 292]\n",
    "\n",
    "for i in rep_two : \n",
    "    x_train[:, i] = replace(x_train[:, i], [np.nan], [-1])\n",
    "    \n",
    "\n",
    "x_train[:, 264] = replace(x_train[:, 264], [np.nan, 99900], [-1, -1])\n",
    "x_train[:, 287] = replace(x_train[:, 287], [np.nan, 99900], [-1, -1])\n",
    "x_train[:, 288] = replace(x_train[:, 288], [np.nan, 99900], [-1, -1])\n",
    "\n",
    "x_train[:, 272] = replace(x_train[:, 272], [np.nan], [0])\n",
    "x_train[:, 273] = replace(x_train[:, 273], [np.nan], [0])\n",
    "\n",
    "x_train[:, 274] = replace(x_train[:, 274], [np.nan], [1])\n",
    "x_train[:, 275] = replace(x_train[:, 275], [np.nan], [1])\n",
    "x_train[:, 280] = replace(x_train[:, 280], [np.nan], [1])\n",
    "x_train[:, 281] = replace(x_train[:, 281], [np.nan], [1])\n",
    "\n",
    "x_train[:, 282] = replace(x_train[:, 282], [np.nan], [2])\n",
    "x_train[:, 283] = replace(x_train[:, 283], [np.nan], [2])\n",
    "\n",
    "x_train[:, 293] = replace(x_train[:, 293], [np.nan, 99000], [np.nan, np.nan])\n",
    "x_train[:, 294] = replace(x_train[:, 294], [np.nan, 99000], [np.nan, np.nan])\n",
    "x_train[:, 297] = replace(x_train[:, 297], [np.nan, 99000], [np.nan, np.nan])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34de0cf-afd8-4ad5-b9e0-c811f0b494fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "We then clean the data by : \n",
    "- removing the nan values by the mean of the rest of the feature\n",
    "- removing the features where the variance is zero since they are constants for all samples\n",
    "- remove the 8 first features as the appear weird in the task of predicting a heart attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad402bc4-2c58-4df7-9eb1-ef201702240b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has now 305 features !\n"
     ]
    }
   ],
   "source": [
    "x_train, zero_var_features = gen_clean(x_train)\n",
    "print(f\"The data has now {x_train.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f33035-a776-4696-af7e-59ce6530e880",
   "metadata": {},
   "source": [
    "# PCA algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f021e6c6-8fb8-443c-86ae-53c473291284",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We can keep the 124 first most influent features given by pca_indices\n"
     ]
    }
   ],
   "source": [
    "pca_indices, idx = pca(x_train)\n",
    "print(f\"We can keep the {idx} first most influent features given by pca_indices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8447e89-f417-40d3-ba06-f143a9c15f69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has now 125 features\n"
     ]
    }
   ],
   "source": [
    "x_train_pca = x_train[:, pca_indices]\n",
    "x_train_pca = x_train_pca[:, :(idx + 1)]\n",
    "print(f\"The data has now {x_train_pca.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c72b15-5138-4306-820f-f1a8f05e471f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f866f3dd-1c9e-47b5-8c3a-7aa9ea4a5a80",
   "metadata": {
    "tags": []
   },
   "source": [
    "We find the Ridge regression solutions using the normal equations.\n",
    "\n",
    "First, we separate our data in a training set (70%) and testing set (30%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d93d42b9-8949-4ef7-9a03-87788189ac3c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tx_tr shape : (229694, 125) ; tx_te shape : (98441, 125)\n",
      "       y_tr : (229694,)     ;        y_te : (98441,)\n"
     ]
    }
   ],
   "source": [
    "tx_tr, tx_te, y_tr, y_te = cross(x_train_pca, y_train, 0.7)\n",
    "\n",
    "print(f\"tx_tr shape : {tx_tr.shape} ; tx_te shape : {tx_te.shape}\")\n",
    "print(f\"       y_tr : {y_tr.shape}     ;        y_te : {y_te.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4637171d-7552-4946-9741-8dcfc84dc7e7",
   "metadata": {},
   "source": [
    "Now we build our models for linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1af13ebb-9521-48cc-b4c1-87822a537f2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data has now 126 features !\n"
     ]
    }
   ],
   "source": [
    "y, tx = build_model_data(tx_tr, y_tr)\n",
    "y_test, tx_test = build_model_data(tx_te, y_te)\n",
    "print(f\"The data has now {tx.shape[1]} features !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13f3d9c-8f9f-4ef5-9900-def4318458c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Linear regression using ridge regression\n",
    "\n",
    "Here we train our model using ridge regression with normal equations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fa1fbe32-f1ab-4847-8ef2-f6bf8582cbf3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of implementations failed: Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Elias\\anaconda3\\envs\\ada\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"C:\\Users\\Elias\\anaconda3\\envs\\ada\\lib\\site-packages\\IPython\\extensions\\autoreload.py\", line 475, in superreload\n",
      "    module = reload(module)\n",
      "  File \"C:\\Users\\Elias\\anaconda3\\envs\\ada\\lib\\importlib\\__init__.py\", line 169, in reload\n",
      "    _bootstrap._exec(spec, module)\n",
      "  File \"<frozen importlib._bootstrap>\", line 613, in _exec\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 846, in exec_module\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 983, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 913, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 228, in _call_with_frames_removed\n",
      "  File \"C:\\Users\\Elias\\OneDrive\\Bureau\\ProG\\ml-project-1-ker\\code\\implementations.py\", line 431\n",
      "    rmse_te.append(np.mean(rmse_te_tmp))\n",
      "    ^\n",
      "SyntaxError: invalid syntax\n",
      "]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ridge_regression_demo' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 6\u001b[0m\n\u001b[0;32m      3\u001b[0m degree \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      4\u001b[0m lambdas \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlogspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m15\u001b[39m)\n\u001b[1;32m----> 6\u001b[0m best_degree, best_lambda, best_rmse \u001b[38;5;241m=\u001b[39m \u001b[43mridge_regression_demo\u001b[49m(tx, tx_test, y, y_test,lambda_,degree)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWe get the best lambda =\u001b[39m\u001b[38;5;124m\"\u001b[39m,best_lambda,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbest degree =\u001b[39m\u001b[38;5;124m\"\u001b[39m, best_degree,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m best rmse =\u001b[39m\u001b[38;5;124m\"\u001b[39m,best_rmse)\n\u001b[0;32m     10\u001b[0m best_weight \u001b[38;5;241m=\u001b[39m ridge_regression(build_poly(tx, best_degree), tx_tr, best_lambda)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ridge_regression_demo' is not defined"
     ]
    }
   ],
   "source": [
    "start_time = datetime.datetime.now()\n",
    "\n",
    "degree = range(10)\n",
    "lambdas = np.logspace(-5, 0, 15)\n",
    "\n",
    "\n",
    "best_degree, best_lambda, best_rmse = ridge_regression_demo(tx, tx_test, y, y_test,lambdas,degree)\n",
    "\n",
    "print(\"We get the best lambda =\",best_lambda,\"and best rmse =\",best_rmse, \"best degree =\",best_degree)\n",
    "\n",
    "best_weight = ridge_regression(y, tx_tr, best_lambda)\n",
    "\n",
    "end_time = datetime.datetime.now()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db5bb5-d9fb-450c-ae3b-9a76dddb2cc3",
   "metadata": {},
   "source": [
    "### Computation of metrics\n",
    "\n",
    "We first compute some metrics on the training data (60% of the total data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "952b615d-3cc8-403a-9396-fcc229589211",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.38854301810234%\n",
      "Precision: 65.57257476294676%\n",
      "Recall : 4.448953333003415%\n",
      "F1-score : 8.33256094169988%\n"
     ]
    }
   ],
   "source": [
    "pred_data = np.dot(tx_tr, best_weight)\n",
    "\n",
    "pred_data[pred_data > 0] = 1\n",
    "pred_data[pred_data < 0] = -1\n",
    "\n",
    "correctly_classified_data = np.sum(pred_data == y)\n",
    "\n",
    "tp = np.sum((pred_data == 1) & (y == 1))\n",
    "fp = np.sum((pred_data == 1) & (y == -1))\n",
    "\n",
    "tn = np.sum((pred_data == -1) & (y == -1))\n",
    "fn = np.sum((pred_data == -1) & (y == 1))\n",
    "\n",
    "accuracy_data = (tp + tn)/(tp + fp + tn + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_data*100}%\")\n",
    "print(f\"Precision: {tp/(tp + fp)*100}%\")\n",
    "print(f\"Recall : {tp/(tp + fn)*100}%\")\n",
    "print(f\"F1-score : {tp/(tp + 0.5*(fn + fp))*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c193f-9520-478f-b06e-131cb186d075",
   "metadata": {
    "tags": []
   },
   "source": [
    "Now we compute some metrics for our test data (40% of the total data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9ac991bb-ded9-4564-9b44-de130c0dad75",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 91.22621671864366%\n",
      "Precision: 61.97440585009141%\n",
      "Recall : 3.8663321167883216%\n",
      "F1-score : 7.278582930756844%\n"
     ]
    }
   ],
   "source": [
    "pred_test = np.dot(tx_te, best_weight)\n",
    "\n",
    "pred_test[pred_test > 0] = 1\n",
    "pred_test[pred_test < 0] = -1\n",
    "\n",
    "correctly_classified_test = np.sum(pred_test == y_test)\n",
    "\n",
    "tp = np.sum((pred_test == 1) & (y_test == 1))\n",
    "fp = np.sum((pred_test == 1) & (y_test == -1))\n",
    "\n",
    "tn = np.sum((pred_test == -1) & (y_test == -1))\n",
    "fn = np.sum((pred_test == -1) & (y_test == 1))\n",
    "\n",
    "accuracy_test = (tp + tn)/(tp + fp + tn + fn)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_test*100}%\")\n",
    "print(f\"Precision: {tp/(tp + fp)*100}%\")\n",
    "print(f\"Recall : {tp/(tp + fn)*100}%\")\n",
    "print(f\"F1-score : {tp/(tp + 0.5*(fn + fp))*100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f956e2bb-b52d-40fa-ae5e-764d58726ce7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f1b800-5139-4f6f-8238-6cbe08cc41b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(w)), np.abs(w))\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Feature Index')\n",
    "plt.ylabel('Weight Value')\n",
    "plt.title('Feature Weights for Analysis')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
